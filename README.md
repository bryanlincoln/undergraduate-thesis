# Intrinsic motivation for robotic manipulation learning with sparse rewards
Machine Learning Algorithms have become increasingly efficient at solving complexreal-world problems. In particular, Reinforcement Learning algorithms are capable oflearning behaviors applicable to robotics that can replace or work together with classicalcontrol models, thereby increasing their robustness, applicability and viability. However,it remains difficult to design reward functions that represent, for a reinforcement learningagent, the task it must perform. Recent research in this area proposes techniques such ascuriosity and intrinsic motivation as an alternative to the use of extrinsic environmentalrewards, proving to be efficient in guiding the agent to satisfactory exploration in gameenvironments such asVizDoomandSuper Mario Bros. This paper analyzes the impact ofthe intrinsic motivation technique on agent training in robotic simulation environments,as well as its general implications for aspects such as generalization, exploration andsampling efficiency. As a result, evidence is found that intrinsic motivation positivelyinfluences the agents’ discovery of complex behaviors, maintaining a tendency for highlevels of exploitation even after it’s convergence.
