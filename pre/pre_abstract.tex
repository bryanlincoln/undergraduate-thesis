\keys{Artificial Intelligence; Reinforcement Learning; Neural Networks; Robotics.}

\begin{abstract}{Intrinsic motivation for robotic manipulation learning with sparse rewards}
Machine Learning Algorithms have become increasingly efficient at solving complex real-world problems. In particular, Reinforcement Learning algorithms are capable of learning behaviors applicable to robotics that can replace or work together with classical control models, thereby increasing their robustness, applicability and viability. However, it remains difficult to design reward functions that represent, for a reinforcement learning agent, the task it must perform. Recent research in this area proposes techniques such as curiosity and intrinsic motivation as an alternative to the use of extrinsic environmental rewards, proving to be efficient in guiding the agent to satisfactory exploration in game environments such as \textit{VizDoom} and \textit{Super Mario Bros}. This paper analyzes the impact of the intrinsic motivation technique on agent training in robotic simulation environments, as well as its general implications for aspects such as generalization, exploration and sampling efficiency. As a result, evidence is found that intrinsic motivation positively influences the agents' discovery of complex behaviors, maintaining a tendency for high levels of exploitation even after it's convergence.

\end{abstract}