\chaves{Inteligência Artificial; Aprendizado por Reforço; Redes Neurais; Robótica.}

\begin{resumo} 
Algoritmos de Aprendizado de Máquina têm se tornado cada vez mais eficientes em resolver problemas complexos do mundo real. Em especial, algoritmos de Aprendizado por Reforço são capazes de aprender comportamentos aplicáveis à robótica que podem substituir ou trabalhar em conjunto de modelos de controle clássico, aumentando assim sua robustez, aplicabilidade e viabilidade. No entanto, resta a dificuldade de se elaborar funções de recompensa que representem, para um agente de aprendizado por reforço, a tarefa que este deve executar. Pesquisas recentes nessa área propõem técnicas como curiosidade e motivação intrínseca como alternativa ao uso de recompensas extrínsecas do ambiente, se mostrando eficientes em guiar o agente a exploração satisfatória em ambientes de jogos como \textit{VizDoom} e \textit{Super Mario Bros}. Neste trabalho é analisado o impacto da técnica de motivação intrínseca no treinamento de agentes em ambientes de simulação robótica, assim como implicações gerais que a mesma tem sobre aspectos como generalização e eficiência de exploração e amostragem nos mesmos. Como resultado, são encontradas evidências de que a motivação intrínseca influencia positivamente na descoberta de comportamentos complexos por parte dos agentes, mantendo uma tendência para altos níveis de exploração mesmo após sua convergência.

\end{resumo}

